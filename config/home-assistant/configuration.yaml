# Home Assistant configuration with Ollama LLM chat integration

homeassistant:
  name: Home
  latitude: !secret latitude
  longitude: !secret longitude
  elevation: 0
  unit_system: metric
  time_zone: Europe/Budapest
  
  external_url: !secret external_url
  internal_url: !secret internal_url

# Configure HTTP
http:
  use_x_forwarded_for: true
  trusted_proxies:
    - 10.0.0.0/8
    - 172.16.0.0/12
    - 192.168.0.0/16

# Default configuration
default_config:

# Text to speech
tts:
  - platform: google_translate
    language: 'hu'

# REST Commands for Ollama LLM
rest_command:
  ollama_chat:
    url: "http://ollama:11434/api/generate"
    method: POST
    headers:
      Content-Type: application/json
    payload: >
      {
        "model": "ministral-3:3b-instruct-2512-q4_K_M",
        "prompt": "[SYSTEM_PROMPT]You are Ministral-3-3B-Instruct-2512, a Large Language Model (LLM) by Mistral AI. The current date is {{ now().strftime('%Y-%m-%d') }}. Yesterday's date is {{ (now() - timedelta(days=1)).strftime('%Y-%m-%d') }}. Respond in the user's language. You cannot browse the web. Use tools if available; if not, explain you cannot perform the action.[/SYSTEM_PROMPT]\n[INST]{{ prompt }}[/INST]",
        "stream": false,
        "temperature": {{ temperature | default(0.7) }},
        "num_predict": {{ max_tokens | default(256) }}
      }
    timeout: 120
 
  ollama_conversation:
    url: "http://ollama:11434/api/generate"
    method: POST
    headers:
      Content-Type: application/json
    payload: >
      {
        "model": "ministral-3:3b-instruct-2512-q4_K_M",
        "prompt": "[SYSTEM_PROMPT]You are Ministral-3-3B-Instruct-2512, a Large Language Model (LLM) by Mistral AI. The current date is {{ now().strftime('%Y-%m-%d') }}. Yesterday's date is {{ (now() - timedelta(days=1)).strftime('%Y-%m-%d') }}. Respond in the user's language. You cannot browse the web. Use tools if available; if not, explain you cannot perform the action.[/SYSTEM_PROMPT]\n[INST]{{ text }}[/INST]",
        "stream": false,
        "temperature": 0.4,
        "num_predict": 150
      }
    timeout: 60

  ollama_health_check:
    url: "http://ollama:11434/api/tags"
    method: GET

# Input Text Helper for Chat
input_text:
  ollama_prompt:
    name: "Ollama Prompt"
    min: 1
    max: 255

  ollama_response:
    name: "Ollama Response"
    min: 0
    max: 255

# Sensors
sensor:
  - platform: rest
    name: "Ollama Status"
    resource: "http://ollama:11434/api/tags"
    method: GET
    value_template: >
      {% if value_json.models is defined %}
        {{ value_json.models | length }}
      {% else %}
        0
      {% endif %}
    unit_of_measurement: "models"
    scan_interval: 300

# Modern Template Sensors
template:
  - sensor:
      - name: "Available Models"
        unit_of_measurement: "count"
        state: >
          {% if state_attr('sensor.ollama_status', 'models') %}
            {{ state_attr('sensor.ollama_status', 'models') | length }}
          {% else %}
            0
          {% endif %}

# Scripts for chatbot interaction
script: !include scripts.yaml

# Intent handlers for Assist
intent_script: !include intent_script.yaml

# Automations
automation: !include automations.yaml

# Scenes
scene: !include scenes.yaml
