# Ollama Conversation Agent - Automatikus Setup

## âœ… AUTOMATIKUS TELEPÃTÃ‰S ENGEDÃ‰LYEZVE!

Az Ollama conversation agent **automatikusan betÃ¶ltÅ‘dik Ã©s beÃ¡llÃ­tÃ³dik** minden Home Assistant indÃ­tÃ¡skor!

### ğŸš€ Mi tÃ¶rtÃ©nik automatikusan:

1. **Home Assistant indÃ­tÃ¡skor:**
   - Ã‰szleli az `ollama_conversation` custom component-et
   - Automatikusan lÃ©trehozza az integrÃ¡ciÃ³t (ha mÃ©g nincs)
   - BeÃ¡llÃ­tja: Host: `http://ollama:11434`, Model: `llama3.2:3b`
   - RegisztrÃ¡lja a conversation agent-et

2. **ÃšjraindÃ­tÃ¡skor:**
   - Minden konfigurÃ¡ciÃ³ megmarad
   - Azonnal hasznÃ¡latra kÃ©sz
   - **Semmi UI-beli teendÅ‘ nincs!**

---

## ğŸ“‹ HasznÃ¡lat (2 lÃ©pÃ©s)

### 1ï¸âƒ£ EllenÅ‘rizd, hogy be van-e Ã¡llÃ­tva

**http://localhost:8123**
- BeÃ¡llÃ­tÃ¡sok â†’ EszkÃ¶zÃ¶k Ã©s SzolgÃ¡ltatÃ¡sok
- Keresd: **"Ollama Conversation"** vagy **"Ollama"**
- Ha megjelenik â†’ âœ… **Automatikusan lÃ©trejÃ¶tt!**

### 2ï¸âƒ£ Chat hasznÃ¡lata!

**Assist megnyitÃ¡sa:**
- Jobb felsÅ‘ sarok â†’ **ğŸ’¬ Chat ikon** 
- Vagy billentyÅ±parancs: **Ctrl + K**

**PÃ©lda kÃ©rdÃ©sek:**
- "Szia! Ki vagy?"
- "Miben tudsz segÃ­teni?"
- "Mi az idÅ‘jÃ¡rÃ¡s?"
- "Kapcsold be a nappaliban a lÃ¡mpÃ¡t"

**Magyar nyelvÅ± vÃ¡laszokat kapsz az Ollama llama3.2:3b model-tÅ‘l!** ğŸ‡­ğŸ‡º

---

## âš™ï¸ OpcionÃ¡lis: ÃllÃ­tsd be mint alapÃ©rtelmezett Assist Agent

Ha szeretnÃ©d, hogy az Ollama legyen **a** beszÃ©lgetÅ‘ Ã¼gynÃ¶k:

1. BeÃ¡llÃ­tÃ¡sok â†’ **Hang Asszisztensek (Voice assistants)**
2. Kattints a **"Home Assistant"** asszisztensre  
3. **BeszÃ©lgetÃ©si Ã¼gynÃ¶k** â†’ vÃ¡laszd: **"Ollama"**
4. **ğŸ’¾ MENTÃ‰S**

EzutÃ¡n **MINDEN** Assist kÃ©rÃ©s az Ollama-n megy keresztÃ¼l!

---

## ğŸ”„ ÃšjraindÃ­tÃ¡s teszt

```powershell
# Home Assistant ÃºjraindÃ­tÃ¡sa
docker restart homeassistant

# VÃ¡rj 30 mÃ¡sodpercet
Start-Sleep -Seconds 30

# EllenÅ‘rzÃ©s
(Invoke-WebRequest http://localhost:8123 -UseBasicParsing).StatusCode
# â†’ 200: mÅ±kÃ¶dik!
```

**ÃšjraindÃ­tÃ¡s utÃ¡n az Ollama agent automatikusan aktÃ­v marad!**

---

## âœ… EllenÅ‘rzÃ©si lista

| Ãllapot | LeÃ­rÃ¡s |
|---------|--------|
| âœ… | Home Assistant fut: http://localhost:8123 |
| âœ… | Ollama API fut: http://localhost:11434 |
| âœ… | llama3.2:3b model betÃ¶ltve |
| âœ… | Custom component automatikusan betÃ¶ltÅ‘dik |
| âœ… | Ollama integrÃ¡ciÃ³ automatikusan lÃ©trejÃ¶n |
| âœ… | ÃšjraindÃ­tÃ¡s utÃ¡n is megmarad |
| â³ | Chat tesztelÃ©se (te csinÃ¡lod)

---

## ğŸ” HibaelhÃ¡rÃ­tÃ¡s

### "Ollama Conversation" nem jelenik meg az integrÃ¡ciÃ³k kÃ¶zÃ¶tt
```powershell
# ÃšjraindÃ­tÃ¡s
docker restart homeassistant
Start-Sleep -Seconds 20

# Logok ellenÅ‘rzÃ©se
docker logs homeassistant --tail=50 | findstr ollama_conversation
```

### "Cannot connect to Ollama" hiba az integrÃ¡ciÃ³ hozzÃ¡adÃ¡sakor
```powershell
# Ollama stÃ¡tusz
docker ps | findstr ollama

# Ollama ÃºjraindÃ­tÃ¡sa
docker restart ollama
Start-Sleep -Seconds 10

# API teszt
curl http://localhost:11434/api/tags
```

### Chat lassÃº vagy nem vÃ¡laszol
- CsÃ¶kkentsd a vÃ¡lasz hosszt: szerkeszd `conversation.py` â†’ `num_predict`: 150 â†’ 100
- Vagy vÃ¡ltsd kisebb modellre: `phi3:mini`

---

## ğŸ¯ Mik tÃ¶rtÃ©ntek a hÃ¡ttÃ©rben?

1. **Custom Component betÃ¶ltÅ‘dÃ¶tt** - Home Assistant felismerte az `ollama_conversation` integrÃ¡ciÃ³t
2. **Config Flow elÃ©rhetÅ‘** - A beÃ¡llÃ­tÃ¡si varÃ¡zslÃ³t hasznÃ¡lhatod a UI-bÃ³l
3. **Conversation Platform regisztrÃ¡lva** - Az agent be tudja fogadni a chat inputokat
4. **Ollama API csatlakozÃ¡s** - `http://ollama:11434` vÃ©gponton elÃ©ri az LLM-et
5. **Magyar nyelvÅ± rendszer prompt** - Minden kÃ©rdÃ©shez hozzÃ¡adva, hogy magyarul vÃ¡laszoljon

---

## ğŸš€ Most menj a UI-ra Ã©s Ã¡llÃ­tsd be!

**http://localhost:8123** â†’ BeÃ¡llÃ­tÃ¡sok â†’ EszkÃ¶zÃ¶k Ã©s SzolgÃ¡ltatÃ¡sok â†’ + IntegrÃ¡ciÃ³ â†’ "Ollama Conversation"

EzutÃ¡n mÃ¡r **chatelhetsz az Ollama-val az Assist-en keresztÃ¼l**! ğŸ‰
