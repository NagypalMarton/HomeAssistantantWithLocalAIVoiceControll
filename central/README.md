# Central Backend - MicroPi Voice Control Service

[![Central Backend CI](https://github.com/NagypalMarton/HomeAssistantantWithLocalAIVoiceControll/actions/workflows/central-ci.yml/badge.svg)](https://github.com/NagypalMarton/HomeAssistantantWithLocalAIVoiceControll/actions/workflows/central-ci.yml)

üöÄ **Edge sz√∂veg feldolgoz√°sa, Home Assistant v√©grehajt√°s, v√°lasz vissza**

## √Åttekint√©s

A **Central Backend** az edge (Raspberry Pi) eszk√∂z√∂kt≈ël kapott felhaszn√°l√≥i sz√∂vegeket feldolgozza:

1. **Intent feldolgoz√°s:** Ollama LLM-en kereszt√ºl (ministral-3:3b) felismeri a parancsot
2. **V√©grehajt√°s:** Per-user Home Assistant instance-en futtatja a parancsot
3. **V√°lasz:** Term√©szetes nyelv≈± v√°laszt k√ºld vissza az edge-nek

Ez egy **diplomamunka projekt**, amely szakmailag konfigur√°lhat√≥, tesztelt √©s dokument√°lt.

## Aktu√°lis Architekt√∫ra

### Service-ek

```
central-postgres      ‚Üí PostgreSQL adatb√°zis (user, session, audit_log)
central-redis         ‚Üí Redis cache (session context)
central-ollama        ‚Üí Ollama LLM (GPU t√°mogat√°s)
central-user-api      ‚Üí FastAPI (intent feldolgoz√°s)
central-ha-manager    ‚Üí Docker-alap√∫ HA instance menedzsment
central-prometheus    ‚Üí Prometheus monitoring (opcion√°lis)
```

### Komponensek r√©szletez√©se

#### 1. **User API Service** (port 8000)
- Intent feldolgoz√°s pipeline
- User autentik√°ci√≥ (JWT)
- Session context kezel√©s
- HA Manager API h√≠v√°sok
- Audit logging
- API endpoints:
  - `POST /api/v1/auth/register` - Regisztr√°ci√≥
  - `POST /api/v1/auth/login` - Bejelentkez√©s
  - `POST /api/v1/intent` - Intent feldolgoz√°s
  - `GET /api/v1/health` - Health check

#### 2. **HA Manager Service** (port 8001)
- Per-user Docker-alap√∫ HA instance lifecycle management
- Automatikus HA container l√©trehoz√°s regisztr√°ci√≥kor
- Port allok√°ci√≥ (8200-8300)
- Volumen kezel√©s
- Container health monitoring
- API endpoints:
  - `POST /api/v1/ha/instance` - HA instance l√©trehoz√°s
  - `GET /api/v1/ha/instance/{user_id}` - HA instance lek√©rdez√©s
  - `DELETE /api/v1/ha/instance/{user_id}` - HA instance t√∂rl√©s
  - `GET /api/v1/ha/instance/{user_id}/status` - Status lek√©rdez√©s

#### 3. **Ollama LLM Service** (port 11434)
- **Modell:** `ministral-3:3b-instruct-2512-q4_K_M`
- **GPU accelerated** (NVIDIA, 4GB vRAM)
- **Chat template:** Ministral-3 nat√≠v format (`[SYSTEM_PROMPT]...[/SYSTEM_PROMPT]`, `[INST]...[/INST]`)
- **Temperature:** 0.15 (determinisztikus output)
- **Context window:** Utols√≥ 10 √ºzenet
- Intent felismer√©s JSON outputtal
- Magyar nyelv≈± prompt engineering
- Timeout: 30 m√°sodperc

#### 4. **Adatb√°zis** (port 5432)
- PostgreSQL 16
- T√°bl√°k:
  - `users` - felhaszn√°l√≥k (email, ha_token_encrypted, role)
  - `sessions` - akt√≠v session-√∂k (context window)
  - `audit_log` - parancs hist√≥ri√°ja (input, intent, HA response, latency)
  - `ha_instances` - per-user HA container metadatai

#### 5. **Redis Cache** (port 6379)
- Session context (rolling window)
- Token blacklist (logout)
- Rate limiting counters

## Technol√≥giai Stack

### Backend
- **Python 3.11**
- **FastAPI** - REST API framework
- **SQLAlchemy** - ORM (async)
- **asyncpg** - PostgreSQL async driver
- **Pydantic** - Data validation
- **python-jose** - JWT handling
- **cryptography** - Token encryption (Fernet)

### Infrastrukt√∫ra
- **Docker Compose** - Service orchestration (dev/staging)
- **PostgreSQL 16** - Relational database
- **Redis 7** - Cache & sessions
- **Ollama** - LLM inference (GPU)

### Monitoring
- **Prometheus** - Metrics collection
- **Structlog** - Structured JSON logging

## Telep√≠t√©s & Ind√≠t√°s

### El≈ëfelt√©telek

- **Docker Engine** (GPU support: NVIDIA Docker Runtime)
- **Docker Compose** v2.0+
- **4GB+ VRAM GPU** (Ollama/Ministral-3 futtat√°s√°hoz)
- **4GB RAM minimum** (Docker containers)
- **20GB szabad t√°rhelyre** (HA instances + Ollama modellek)

### L√©p√©sek

1. **Repository kl√≥noz√°sa**
```bash
cd central
```

2. **Automatikus ind√≠t√°s (egyszer≈± m√≥dszer)**

**Linux/Mac:**
```bash
chmod +x start.sh
./start.sh
```

**Windows (PowerShell):**
```powershell
.\start.ps1
```

Ez a script automatikusan:
- ‚úÖ L√©trehozza a `.env` f√°jlt ha nincs
- ‚úÖ Gener√°l biztons√°gos `JWT_SECRET` √©s `ENCRYPTION_KEY` kulcsokat
- ‚úÖ Elind√≠tja az √∂sszes Docker service-t
- ‚úÖ Ellen≈ërzi a health check-eket

**Vagy manu√°lis ind√≠t√°s:**
```bash
# 1. Environment be√°ll√≠t√°sa (els≈ë alkalommal)
docker-compose --profile setup run --rm init

# 2. Services ind√≠t√°sa
docker-compose up -d
```

3. **Ollama modell bet√∂lt√©se**
```bash
docker exec central-ollama ollama pull ministral-3:3b-instruct-2512-q4_K_M
```

4. **Service-ek ellen≈ërz√©se**
```bash
docker-compose ps
docker-compose logs -f user-api
```

5. **Health check**
```bash
curl http://localhost:8000/api/v1/health
curl http://localhost:8001/api/v1/health
curl http://localhost:11434/api/tags
```

## API V√©gpontok

### Intent Processing
```
POST /api/v1/intent
Authorization: Bearer <JWT_TOKEN>
Content-Type: application/json

{
  "user_id": "uuid",
  "device_id": "raspberry-pi-1",
  "text": "Kapcsold be a nappali l√°mp√°t",
  "session_id": "optional-session-uuid"
}

Response:
{
  "request_id": "uuid",
  "intent": "turn_on",
  "entity_id": "light.nappali",
  "response": "Bekapcsoltam a nappali l√°mp√°t.",
  "status": "success",
  "confidence": 0.95,
  "latency_ms": 245
}
```

### HA Instance Management
```
POST /api/v1/ha/instance
{
  "user_id": "uuid"
}

Response:
{
  "user_id": "uuid",
  "container_id": "abc123...",
  "container_name": "ha-user-12345678",
  "status": "running",
  "host_port": 8200,
  "timezone": "Europe/Budapest"
}
```

## Fejleszt√©si St√°tusz

### Implement√°lva ‚úÖ
- [x] Docker Compose setup (GPU support)
- [x] User API alapstrukt√∫ra
- [x] Ollama LLM service integration
- [x] Intent processing pipeline (LLM)
- [x] Token encryption (Fernet)
- [x] HA Manager service alapstrukt√∫ra
- [x] Docker container management
- [x] PostgreSQL + Redis setup

### TODO üöß
- [ ] Alembic migrations
- [ ] HA Manager - User API integr√°ci√≥
- [ ] Audit logging (DB persistence)
- [ ] Session context management (Redis)
- [ ] HA parancs v√©grehajt√°s integr√°ci√≥ja
- [ ] Rate limiting implement√°ci√≥
- [ ] Error handling & fallbacks
- [ ] Unit & integration tests
- [ ] Prometheus metrics refinement
- [ ] Performance optimization

## Biztons√°gi Aspektusok

- ‚úÖ JWT-alap√∫ autentik√°ci√≥
- ‚úÖ Token encryption (Home Assistant API tokenekhez)
- ‚úÖ SQL injection v√©delem (SQLAlchemy parameterization)
- ‚úÖ CORS configured
- ‚úÖ Per-user HA instance izol√°lts√°ga (Docker network)
- üöß Rate limiting
- üöß Request validation
- üöß Audit trail

## Monitoring & Logging

### Struktur√°lt Logging
- **Format:** JSON
- **Library:** structlog
- **Szintek:** INFO, WARNING, ERROR
- **Mez≈ëk:** timestamp, request_id, user_id, latency_ms, error

### Prometheus Metrik√°k
- Request latency
- Request count by endpoint
- Error rate
- LLM response time
- Database query duration
- Service health checks
- Container resource usage
- Database metrics

## Fejleszt≈ëi √ötmutat√≥

### Helyi fejleszt√©s

1. **Python venv**
```bash
cd services/user-api
python -m venv venv
source venv/bin/activate  # Linux/Mac
# vagy: venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

2. **Database setup**
```bash
# Docker postgres start
docker-compose up -d postgres redis ollama

# Migrations (k√©s≈ëbb Alembic)
# sqlalchemy models automatikusan l√©trehoznak t√°bl√°kat init_db-vel
```

3. **Local development**
```bash
cd services/user-api
uvicorn main:app --reload --port 8000
```

### Testing

```bash
# Unit tests
pytest services/user-api/tests/ -v

# Coverage
pytest --cov=app services/user-api/tests/
```

## Troubleshooting

### Ollama GPU error
```
Error: CUDA device not found
‚Üí Ellen≈ërizd az NVIDIA Docker Runtime-ot: docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

### Port m√°r foglalt
```
docker-compose down
# vagy: lsof -i :8000 / netstat -tulpn
```

### Database connection error
```
docker-compose logs postgres
# Check: POSTGRES_USER, POSTGRES_PASSWORD env vars
```

## Kapcsol√≥d√≥ Dokumentumok

- [Szoftverk√∂vetelm√©ny-specifik√°ci√≥](../docs/central_srs.md)
- [Edge telep√≠t√©si √∫tmutat√≥](../edge/README.md)
- [Projekt strukt√∫ra](../README.md)
- [Zabbix monitoring](./monitoring/ZABBIX.md) (k√©s≈ëbb)

## K√∂zrem≈±k√∂d√©s

A central backend fejleszt√©se folyamatban. K√©rd√©sek, PR-ok √©s javaslatok v√°rhat√≥ak! üöÄ

